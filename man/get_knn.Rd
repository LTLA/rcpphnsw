% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hnsw.R
\name{get_knn}
\alias{get_knn}
\title{Find Nearest Neighbors and Euclidean Distances}
\usage{
get_knn(X, k = 10, include_self = TRUE, M = 200, ef = 16)
}
\arguments{
\item{X}{a numeric matrix of data to add. Each of the n rows is an item in the index.}

\item{k}{Number of neighbors to return.}

\item{include_self}{If \code{TRUE}, return the item itself as one of its
\code{k}-neighbors.}

\item{M}{Controls maximum number of neighbors in the zero and above-zero
layers. Higher values lead to better recall and shorter retrieval times, at
the expense of longer indexing time. Suggested range: 5-100 (default: 16).}

\item{ef}{Controls the quality of the graph. Higher values lead to improved
recall at the expense of longer build time. Suggested range: 100-2000
(default: 200).}
}
\value{
a list containing:
\itemize{
  \item \code{idx} an n by k matrix containing the nearest neighbor indices.
  \item \code{dist} an n by k matrix containing the nearest neighbor Euclidean
     distances.
}
}
\description{
A k-nearest neighbor algorithm using the HNSW library (\url{https://github.com/nmslib/hnsw}).
}
\details{
This function also demonstrates how to use the minimal interface to HNSW to do something
non-trivial. The class used, "HnswL2", uses the "Squared L2" distance, which is the square
of the Euclidean distance. This function takes care of the square root for you, so returns
actual Euclidean distances.
}
\examples{
get_knn(as.matrix(iris[, -5]), k = 10)
}
